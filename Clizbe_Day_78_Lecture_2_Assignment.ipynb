{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Clizbe Day 78 Lecture 2 Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidclizbe/datascience/blob/master/Clizbe_Day_78_Lecture_2_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vEszfzSgGvb"
      },
      "source": [
        "## Day 83 Lecture 2 Assignment\n",
        "\n",
        "In this assignment, we will learn about other optimization algorithms. We will create a neural network and try out the different optimization algorithms and compare their performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grVMFvpMgGvd"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "from  tensorflow.keras.optimizers import SGD, Adagrad, Adam, RMSprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJfwGXExgGvf"
      },
      "source": [
        "In this assignment, we will be using the cancer data that we have worked with in previous lessons. The pre-processed data is loaded below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itA0U381gGvg"
      },
      "source": [
        "cancer = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/cancer_processed.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocNzndc-gGvi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "82c302c7-c92e-4b92-f5f3-2e68ca7cd562"
      },
      "source": [
        "cancer.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  fractal_dimension_mean  diagnosis\n",
              "0        17.99         10.38  ...                 0.07871          M\n",
              "1        20.57         17.77  ...                 0.05667          M\n",
              "2        19.69         21.25  ...                 0.05999          M\n",
              "3        11.42         20.38  ...                 0.09744          M\n",
              "4        20.29         14.34  ...                 0.05883          M\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMyeFkQTgGvm"
      },
      "source": [
        "As you may recall, diagnosis is the target variable. One hot encode the diagnosis column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tCQR6LjgGvn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "553d597d-202d-4215-a95c-e4bb61327fac"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "diagnosis_dummies = pd.get_dummies(cancer['diagnosis'], drop_first=True)\n",
        "\n",
        "diagnosis_dummies"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     M\n",
              "0    1\n",
              "1    1\n",
              "2    1\n",
              "3    1\n",
              "4    1\n",
              "..  ..\n",
              "564  1\n",
              "565  1\n",
              "566  1\n",
              "567  1\n",
              "568  0\n",
              "\n",
              "[569 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2-HyWovs-X-"
      },
      "source": [
        "malignant = diagnosis_dummies['M']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOtEVsz6rgrv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "b7041f0b-1cc4-4551-fcd5-fa54aee32ca2"
      },
      "source": [
        "malignant"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "      ..\n",
              "564    1\n",
              "565    1\n",
              "566    1\n",
              "567    1\n",
              "568    0\n",
              "Name: M, Length: 569, dtype: uint8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0olvIspostc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "88b883ee-3784-4a58-b96c-42616878bc3a"
      },
      "source": [
        "cancer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     radius_mean  texture_mean  ...  fractal_dimension_mean  diagnosis\n",
              "0          17.99         10.38  ...                 0.07871          M\n",
              "1          20.57         17.77  ...                 0.05667          M\n",
              "2          19.69         21.25  ...                 0.05999          M\n",
              "3          11.42         20.38  ...                 0.09744          M\n",
              "4          20.29         14.34  ...                 0.05883          M\n",
              "..           ...           ...  ...                     ...        ...\n",
              "564        21.56         22.39  ...                 0.05623          M\n",
              "565        20.13         28.25  ...                 0.05533          M\n",
              "566        16.60         28.08  ...                 0.05648          M\n",
              "567        20.60         29.33  ...                 0.07016          M\n",
              "568         7.76         24.54  ...                 0.05884          B\n",
              "\n",
              "[569 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iagdEcoIrm8P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "7577d10a-5576-4e6b-8bc4-c72b71a74c2a"
      },
      "source": [
        "cancer = cancer.join(diagnosis_dummies) \n",
        "cancer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>B</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     radius_mean  texture_mean  ...  diagnosis  M\n",
              "0          17.99         10.38  ...          M  1\n",
              "1          20.57         17.77  ...          M  1\n",
              "2          19.69         21.25  ...          M  1\n",
              "3          11.42         20.38  ...          M  1\n",
              "4          20.29         14.34  ...          M  1\n",
              "..           ...           ...  ...        ... ..\n",
              "564        21.56         22.39  ...          M  1\n",
              "565        20.13         28.25  ...          M  1\n",
              "566        16.60         28.08  ...          M  1\n",
              "567        20.60         29.33  ...          M  1\n",
              "568         7.76         24.54  ...          B  0\n",
              "\n",
              "[569 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHKiiXNCtuqk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "257db11b-149f-4ec0-dcad-cb714aee3766"
      },
      "source": [
        "cancer = cancer.drop(['diagnosis'], axis=1)\n",
        "cancer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     radius_mean  texture_mean  ...  fractal_dimension_mean  M\n",
              "0          17.99         10.38  ...                 0.07871  1\n",
              "1          20.57         17.77  ...                 0.05667  1\n",
              "2          19.69         21.25  ...                 0.05999  1\n",
              "3          11.42         20.38  ...                 0.09744  1\n",
              "4          20.29         14.34  ...                 0.05883  1\n",
              "..           ...           ...  ...                     ... ..\n",
              "564        21.56         22.39  ...                 0.05623  1\n",
              "565        20.13         28.25  ...                 0.05533  1\n",
              "566        16.60         28.08  ...                 0.05648  1\n",
              "567        20.60         29.33  ...                 0.07016  1\n",
              "568         7.76         24.54  ...                 0.05884  0\n",
              "\n",
              "[569 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcJDxAb7gGvp"
      },
      "source": [
        "Split the data into train and test with 20% of the data in test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4TciqK3u_V1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "be9d304e-0e96-4241-88ee-7c7d02bb412a"
      },
      "source": [
        "X = cancer.drop(['M'], axis=1)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     radius_mean  texture_mean  ...  symmetry_mean  fractal_dimension_mean\n",
              "0          17.99         10.38  ...         0.2419                 0.07871\n",
              "1          20.57         17.77  ...         0.1812                 0.05667\n",
              "2          19.69         21.25  ...         0.2069                 0.05999\n",
              "3          11.42         20.38  ...         0.2597                 0.09744\n",
              "4          20.29         14.34  ...         0.1809                 0.05883\n",
              "..           ...           ...  ...            ...                     ...\n",
              "564        21.56         22.39  ...         0.1726                 0.05623\n",
              "565        20.13         28.25  ...         0.1752                 0.05533\n",
              "566        16.60         28.08  ...         0.1590                 0.05648\n",
              "567        20.60         29.33  ...         0.2397                 0.07016\n",
              "568         7.76         24.54  ...         0.1587                 0.05884\n",
              "\n",
              "[569 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPUe_US9yiV7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "8f6d0be5-b86a-42b1-ea22-ed2a9fd4f8d8"
      },
      "source": [
        "y = cancer['M']\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "      ..\n",
              "564    1\n",
              "565    1\n",
              "566    1\n",
              "567    1\n",
              "568    0\n",
              "Name: M, Length: 569, dtype: uint8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9DgU09lgGvq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "38aa2f6f-a902-45ef-deb2-7e66abf7d31c"
      },
      "source": [
        "# Answer below\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>17.270</td>\n",
              "      <td>25.42</td>\n",
              "      <td>112.40</td>\n",
              "      <td>928.8</td>\n",
              "      <td>0.08331</td>\n",
              "      <td>0.11090</td>\n",
              "      <td>0.12040</td>\n",
              "      <td>0.05736</td>\n",
              "      <td>0.1467</td>\n",
              "      <td>0.05407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>18.660</td>\n",
              "      <td>17.12</td>\n",
              "      <td>121.40</td>\n",
              "      <td>1077.0</td>\n",
              "      <td>0.10540</td>\n",
              "      <td>0.11000</td>\n",
              "      <td>0.14570</td>\n",
              "      <td>0.08665</td>\n",
              "      <td>0.1966</td>\n",
              "      <td>0.06213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>10.940</td>\n",
              "      <td>18.59</td>\n",
              "      <td>70.39</td>\n",
              "      <td>370.0</td>\n",
              "      <td>0.10040</td>\n",
              "      <td>0.07460</td>\n",
              "      <td>0.04944</td>\n",
              "      <td>0.02932</td>\n",
              "      <td>0.1486</td>\n",
              "      <td>0.06615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>11.870</td>\n",
              "      <td>21.54</td>\n",
              "      <td>76.83</td>\n",
              "      <td>432.0</td>\n",
              "      <td>0.06613</td>\n",
              "      <td>0.10640</td>\n",
              "      <td>0.08777</td>\n",
              "      <td>0.02386</td>\n",
              "      <td>0.1349</td>\n",
              "      <td>0.06612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>9.173</td>\n",
              "      <td>13.86</td>\n",
              "      <td>59.20</td>\n",
              "      <td>260.9</td>\n",
              "      <td>0.07721</td>\n",
              "      <td>0.08751</td>\n",
              "      <td>0.05988</td>\n",
              "      <td>0.02180</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.06963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>19.680</td>\n",
              "      <td>21.68</td>\n",
              "      <td>129.90</td>\n",
              "      <td>1194.0</td>\n",
              "      <td>0.09797</td>\n",
              "      <td>0.13390</td>\n",
              "      <td>0.18630</td>\n",
              "      <td>0.11030</td>\n",
              "      <td>0.2082</td>\n",
              "      <td>0.05715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>24.250</td>\n",
              "      <td>20.20</td>\n",
              "      <td>166.20</td>\n",
              "      <td>1761.0</td>\n",
              "      <td>0.14470</td>\n",
              "      <td>0.28670</td>\n",
              "      <td>0.42680</td>\n",
              "      <td>0.20120</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.06877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>11.750</td>\n",
              "      <td>20.18</td>\n",
              "      <td>76.10</td>\n",
              "      <td>419.8</td>\n",
              "      <td>0.10890</td>\n",
              "      <td>0.11410</td>\n",
              "      <td>0.06843</td>\n",
              "      <td>0.03738</td>\n",
              "      <td>0.1993</td>\n",
              "      <td>0.06453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>16.780</td>\n",
              "      <td>18.80</td>\n",
              "      <td>109.30</td>\n",
              "      <td>886.3</td>\n",
              "      <td>0.08865</td>\n",
              "      <td>0.09182</td>\n",
              "      <td>0.08422</td>\n",
              "      <td>0.06576</td>\n",
              "      <td>0.1893</td>\n",
              "      <td>0.05534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>7.729</td>\n",
              "      <td>25.49</td>\n",
              "      <td>47.98</td>\n",
              "      <td>178.8</td>\n",
              "      <td>0.08098</td>\n",
              "      <td>0.04878</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1870</td>\n",
              "      <td>0.07285</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>455 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     radius_mean  texture_mean  ...  symmetry_mean  fractal_dimension_mean\n",
              "441       17.270         25.42  ...         0.1467                 0.05407\n",
              "121       18.660         17.12  ...         0.1966                 0.06213\n",
              "405       10.940         18.59  ...         0.1486                 0.06615\n",
              "450       11.870         21.54  ...         0.1349                 0.06612\n",
              "63         9.173         13.86  ...         0.2341                 0.06963\n",
              "..           ...           ...  ...            ...                     ...\n",
              "343       19.680         21.68  ...         0.2082                 0.05715\n",
              "122       24.250         20.20  ...         0.2655                 0.06877\n",
              "160       11.750         20.18  ...         0.1993                 0.06453\n",
              "167       16.780         18.80  ...         0.1893                 0.05534\n",
              "538        7.729         25.49  ...         0.1870                 0.07285\n",
              "\n",
              "[455 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOYKha3qutLd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "441bc824-0470-4d0b-d82b-6b565b5c3139"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "441    1\n",
              "121    1\n",
              "405    0\n",
              "450    0\n",
              "63     0\n",
              "      ..\n",
              "343    1\n",
              "122    1\n",
              "160    0\n",
              "167    1\n",
              "538    0\n",
              "Name: M, Length: 455, dtype: uint8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eghtF43gGvk"
      },
      "source": [
        "Scale all other variables using the standard scaler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7cjZatEgGvk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "ec18b6f7-b37b-4a2f-ed35-96dcb1308ad9"
      },
      "source": [
        "# Answer below:\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_Scaled = scaler.fit_transform(X_train)\n",
        "X_train_Scaled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.01052448,  1.44148513,  0.95490513, ...,  0.29707386,\n",
              "        -1.26435674, -1.27441708],\n",
              "       [ 1.43058368, -0.47383087,  1.34845236, ...,  1.09226476,\n",
              "         0.57260622, -0.09589678],\n",
              "       [-0.90240698, -0.13461225, -0.88208591, ..., -0.46418093,\n",
              "        -1.19441226,  0.49190119],\n",
              "       ...,\n",
              "       [-0.65762428,  0.23229768, -0.63240206, ..., -0.2453609 ,\n",
              "         0.67200101,  0.25502739],\n",
              "       [ 0.86244606, -0.08615245,  0.81934997, ...,  0.52512451,\n",
              "         0.30387216, -1.08871972],\n",
              "       [-1.87277395,  1.45763839, -1.86201853, ..., -1.26018629,\n",
              "         0.21920253,  1.47156448]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgQOTqIZwcHJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "f4da637a-cfd2-4293-8327-39cff24f49d6"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "X_test_Scaled = scaler.fit_transform(X_test)\n",
        "\n",
        "X_test_Scaled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.48957037, -0.98469068, -0.47298607, ..., -0.56445501,\n",
              "        -1.35932892, -0.444944  ],\n",
              "       [ 0.64063486,  0.8686517 ,  0.75016127, ...,  0.93227802,\n",
              "        -0.42543029,  1.38089227],\n",
              "       [ 0.06953328,  2.63940739,  0.20373806, ...,  0.79885883,\n",
              "         1.10276746,  1.10459766],\n",
              "       ...,\n",
              "       [-0.08404025, -1.48021079, -0.11535908, ..., -0.34795924,\n",
              "        -0.27331802, -0.82055188],\n",
              "       [-0.70313357,  2.05887157, -0.72903439, ..., -0.89066606,\n",
              "        -0.71196737, -0.22976525],\n",
              "       [ 0.56864727, -0.6494859 ,  0.5399985 , ...,  0.55595012,\n",
              "        -0.0115434 , -0.85492955]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 296
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTOKHMqrgGvr"
      },
      "source": [
        "Generate a sequential model consisting of 5 layers. The layers should be of size 128, 64, 32, 32, 1. Use the appropriate activation for the output layer based on the type of prediction algorithm we are producing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMLvn0PcxSmI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e44da6f2-31ed-4277-aea4-9e7ee4ac19ad"
      },
      "source": [
        "shape = X_train_Scaled.shape\n",
        "shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(455, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuLbt7X2gGvs"
      },
      "source": [
        "# Answer below\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim = 10 , activation= 'relu'))\n",
        "model.add(Dense( 64, activation= 'relu'))\n",
        "model.add(Dense(32, activation= 'relu'))\n",
        "model.add(Dense(32, activation= 'relu'))\n",
        "model.add(Dense(1, activation= 'sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLyq5KXtgGvt"
      },
      "source": [
        "Initialize a SGD optimizer with learning rate 0.05 and momentum 0.9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlNXLxoUgGvu"
      },
      "source": [
        "# Answer below:\n",
        "sgd = SGD(learning_rate= .05, momentum=.9)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-O0YHk_gGvv"
      },
      "source": [
        "Compile and fit the model using the appropriate loss function and metric and use the optimizers defined above.\n",
        "\n",
        "batch size = 100, epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD9IZdHMgGvw"
      },
      "source": [
        "# Answer below:\n",
        "model.compile(optimizer=sgd, loss= 'binary_crossentropy', metrics= ['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWV-6wAgyAVz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "127fe76b-9bcb-495a-f534-b530cab200cb"
      },
      "source": [
        "model.fit(X_train_Scaled, y_train, batch_size=100, epochs= 200, verbose= 1, validation_data=(X_test_Scaled, y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6415 - accuracy: 0.7385 - val_loss: 0.5237 - val_accuracy: 0.8596\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.9253 - val_loss: 0.3104 - val_accuracy: 0.8684\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2079 - accuracy: 0.9341 - val_loss: 0.2034 - val_accuracy: 0.8947\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1620 - accuracy: 0.9319 - val_loss: 0.1475 - val_accuracy: 0.9211\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1520 - accuracy: 0.9473 - val_loss: 0.1405 - val_accuracy: 0.9386\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1472 - accuracy: 0.9451 - val_loss: 0.1272 - val_accuracy: 0.9386\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1303 - accuracy: 0.9538 - val_loss: 0.1415 - val_accuracy: 0.9211\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1181 - accuracy: 0.9538 - val_loss: 0.1011 - val_accuracy: 0.9561\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1058 - accuracy: 0.9648 - val_loss: 0.1312 - val_accuracy: 0.9211\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9648 - val_loss: 0.1138 - val_accuracy: 0.9386\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0975 - accuracy: 0.9692 - val_loss: 0.1214 - val_accuracy: 0.9298\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0919 - accuracy: 0.9670 - val_loss: 0.1375 - val_accuracy: 0.9211\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0906 - accuracy: 0.9692 - val_loss: 0.1443 - val_accuracy: 0.9211\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9714 - val_loss: 0.1130 - val_accuracy: 0.9386\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0862 - accuracy: 0.9692 - val_loss: 0.1515 - val_accuracy: 0.9211\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0819 - accuracy: 0.9692 - val_loss: 0.1455 - val_accuracy: 0.9298\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9692 - val_loss: 0.1420 - val_accuracy: 0.9386\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0754 - accuracy: 0.9714 - val_loss: 0.1650 - val_accuracy: 0.9211\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0725 - accuracy: 0.9758 - val_loss: 0.1577 - val_accuracy: 0.9298\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0714 - accuracy: 0.9780 - val_loss: 0.1813 - val_accuracy: 0.9123\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.9758 - val_loss: 0.1589 - val_accuracy: 0.9298\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0681 - accuracy: 0.9758 - val_loss: 0.1626 - val_accuracy: 0.9211\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0627 - accuracy: 0.9802 - val_loss: 0.1736 - val_accuracy: 0.9123\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.9802 - val_loss: 0.1823 - val_accuracy: 0.9123\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0579 - accuracy: 0.9780 - val_loss: 0.1885 - val_accuracy: 0.9298\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.9780 - val_loss: 0.1850 - val_accuracy: 0.9211\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0538 - accuracy: 0.9824 - val_loss: 0.2212 - val_accuracy: 0.9035\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.9758 - val_loss: 0.2112 - val_accuracy: 0.9123\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.9714 - val_loss: 0.2067 - val_accuracy: 0.9211\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0616 - accuracy: 0.9714 - val_loss: 0.2908 - val_accuracy: 0.8947\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9802 - val_loss: 0.2038 - val_accuracy: 0.9211\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.9758 - val_loss: 0.2984 - val_accuracy: 0.9035\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0528 - accuracy: 0.9846 - val_loss: 0.1484 - val_accuracy: 0.9386\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9714 - val_loss: 0.2724 - val_accuracy: 0.9035\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.9802 - val_loss: 0.2254 - val_accuracy: 0.9298\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0466 - accuracy: 0.9846 - val_loss: 0.1513 - val_accuracy: 0.9386\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.9758 - val_loss: 0.3122 - val_accuracy: 0.9035\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9890 - val_loss: 0.2373 - val_accuracy: 0.9386\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.9802 - val_loss: 0.3759 - val_accuracy: 0.9123\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9824 - val_loss: 0.2354 - val_accuracy: 0.9298\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9780 - val_loss: 0.3058 - val_accuracy: 0.9035\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0488 - accuracy: 0.9846 - val_loss: 0.3438 - val_accuracy: 0.8947\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0339 - accuracy: 0.9868 - val_loss: 0.2104 - val_accuracy: 0.9298\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0366 - accuracy: 0.9824 - val_loss: 0.3311 - val_accuracy: 0.9035\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0321 - accuracy: 0.9868 - val_loss: 0.2457 - val_accuracy: 0.9211\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 0.3007 - val_accuracy: 0.9123\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 0.9890 - val_loss: 0.2952 - val_accuracy: 0.9035\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9912 - val_loss: 0.2915 - val_accuracy: 0.9123\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0229 - accuracy: 0.9912 - val_loss: 0.3463 - val_accuracy: 0.8860\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 0.9978 - val_loss: 0.3010 - val_accuracy: 0.9035\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9956 - val_loss: 0.3752 - val_accuracy: 0.8860\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0196 - accuracy: 0.9890 - val_loss: 0.3391 - val_accuracy: 0.9035\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0184 - accuracy: 0.9978 - val_loss: 0.3644 - val_accuracy: 0.8947\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9978 - val_loss: 0.3783 - val_accuracy: 0.8947\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 0.9956 - val_loss: 0.4134 - val_accuracy: 0.8947\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.4162 - val_accuracy: 0.8947\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.4915 - val_accuracy: 0.8860\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.4437 - val_accuracy: 0.8860\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 0.9956 - val_loss: 0.4830 - val_accuracy: 0.8860\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9956 - val_loss: 0.4750 - val_accuracy: 0.8860\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9978 - val_loss: 0.5673 - val_accuracy: 0.8860\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9956 - val_loss: 0.4650 - val_accuracy: 0.8947\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9978 - val_loss: 0.5762 - val_accuracy: 0.8860\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.5370 - val_accuracy: 0.8860\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9956 - val_loss: 0.6440 - val_accuracy: 0.8860\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.6089 - val_accuracy: 0.8860\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.6231 - val_accuracy: 0.8860\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6105 - val_accuracy: 0.8860\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6801 - val_accuracy: 0.8860\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.5854 - val_accuracy: 0.8860\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.7337 - val_accuracy: 0.8860\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6869 - val_accuracy: 0.8860\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.8860\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.7275 - val_accuracy: 0.8860\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.7730 - val_accuracy: 0.8772\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9956 - val_loss: 0.6532 - val_accuracy: 0.8860\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.8585 - val_accuracy: 0.8860\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9978 - val_loss: 0.6012 - val_accuracy: 0.8860\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 0.9978 - val_loss: 0.9865 - val_accuracy: 0.8772\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0183 - accuracy: 0.9956 - val_loss: 0.6048 - val_accuracy: 0.8860\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 0.9816 - val_accuracy: 0.8772\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.5846 - val_accuracy: 0.8947\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0160 - accuracy: 0.9934 - val_loss: 0.8762 - val_accuracy: 0.8772\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0495 - accuracy: 0.9802 - val_loss: 0.3878 - val_accuracy: 0.9298\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0309 - accuracy: 0.9868 - val_loss: 1.0716 - val_accuracy: 0.8772\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0773 - accuracy: 0.9758 - val_loss: 0.4043 - val_accuracy: 0.9211\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9758 - val_loss: 0.8437 - val_accuracy: 0.8860\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0524 - accuracy: 0.9780 - val_loss: 0.6817 - val_accuracy: 0.8947\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0210 - accuracy: 0.9912 - val_loss: 0.8109 - val_accuracy: 0.8860\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0386 - accuracy: 0.9912 - val_loss: 0.8234 - val_accuracy: 0.8684\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.6845 - val_accuracy: 0.8772\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0222 - accuracy: 0.9912 - val_loss: 0.7232 - val_accuracy: 0.8860\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9890 - val_loss: 0.7388 - val_accuracy: 0.8684\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 0.9934 - val_loss: 0.7355 - val_accuracy: 0.8772\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9934 - val_loss: 0.6056 - val_accuracy: 0.8772\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.6972 - val_accuracy: 0.8772\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9956 - val_loss: 0.6856 - val_accuracy: 0.8860\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6243 - val_accuracy: 0.8860\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0189 - accuracy: 0.9912 - val_loss: 0.6138 - val_accuracy: 0.8772\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.9934 - val_loss: 0.7925 - val_accuracy: 0.8772\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9956 - val_loss: 0.8760 - val_accuracy: 0.8772\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9934 - val_loss: 0.7178 - val_accuracy: 0.8860\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.9020 - val_accuracy: 0.8684\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.8276 - val_accuracy: 0.8772\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.9956 - val_loss: 0.7808 - val_accuracy: 0.8772\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8984 - val_accuracy: 0.8860\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.9978 - val_loss: 0.8299 - val_accuracy: 0.8772\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7839 - val_accuracy: 0.8860\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8311 - val_accuracy: 0.8772\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8138 - val_accuracy: 0.8772\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7854 - val_accuracy: 0.8860\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8021 - val_accuracy: 0.8772\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8365 - val_accuracy: 0.8772\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8457 - val_accuracy: 0.8772\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8630 - val_accuracy: 0.8772\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8816 - val_accuracy: 0.8772\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8814 - val_accuracy: 0.8772\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8931 - val_accuracy: 0.8772\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9003 - val_accuracy: 0.8772\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8923 - val_accuracy: 0.8772\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9237 - val_accuracy: 0.8772\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9357 - val_accuracy: 0.8772\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9217 - val_accuracy: 0.8772\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9288 - val_accuracy: 0.8772\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9405 - val_accuracy: 0.8772\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9372 - val_accuracy: 0.8772\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9501 - val_accuracy: 0.8772\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9490 - val_accuracy: 0.8772\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9713 - val_accuracy: 0.8772\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 9.6180e-04 - accuracy: 1.0000 - val_loss: 0.9871 - val_accuracy: 0.8772\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 9.4485e-04 - accuracy: 1.0000 - val_loss: 0.9842 - val_accuracy: 0.8772\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 9.9162e-04 - accuracy: 1.0000 - val_loss: 0.9793 - val_accuracy: 0.8772\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 9.4322e-04 - accuracy: 1.0000 - val_loss: 1.0049 - val_accuracy: 0.8772\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8.5066e-04 - accuracy: 1.0000 - val_loss: 1.0139 - val_accuracy: 0.8772\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8.2933e-04 - accuracy: 1.0000 - val_loss: 1.0035 - val_accuracy: 0.8772\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8.5789e-04 - accuracy: 1.0000 - val_loss: 1.0118 - val_accuracy: 0.8772\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7.8119e-04 - accuracy: 1.0000 - val_loss: 1.0052 - val_accuracy: 0.8772\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8.0671e-04 - accuracy: 1.0000 - val_loss: 1.0187 - val_accuracy: 0.8772\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7.5735e-04 - accuracy: 1.0000 - val_loss: 1.0385 - val_accuracy: 0.8772\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 7.5802e-04 - accuracy: 1.0000 - val_loss: 1.0545 - val_accuracy: 0.8772\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7.5444e-04 - accuracy: 1.0000 - val_loss: 1.0577 - val_accuracy: 0.8772\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7.4321e-04 - accuracy: 1.0000 - val_loss: 1.0439 - val_accuracy: 0.8772\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7.0578e-04 - accuracy: 1.0000 - val_loss: 1.0574 - val_accuracy: 0.8772\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7.1997e-04 - accuracy: 1.0000 - val_loss: 1.0595 - val_accuracy: 0.8772\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7.5934e-04 - accuracy: 1.0000 - val_loss: 1.0410 - val_accuracy: 0.8772\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 6.7234e-04 - accuracy: 1.0000 - val_loss: 1.0671 - val_accuracy: 0.8772\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 6.6080e-04 - accuracy: 1.0000 - val_loss: 1.0922 - val_accuracy: 0.8772\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 6.6226e-04 - accuracy: 1.0000 - val_loss: 1.0871 - val_accuracy: 0.8772\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 6.1921e-04 - accuracy: 1.0000 - val_loss: 1.0843 - val_accuracy: 0.8772\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.9367e-04 - accuracy: 1.0000 - val_loss: 1.0738 - val_accuracy: 0.8772\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 6.2002e-04 - accuracy: 1.0000 - val_loss: 1.0881 - val_accuracy: 0.8772\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.7097e-04 - accuracy: 1.0000 - val_loss: 1.0905 - val_accuracy: 0.8772\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.8263e-04 - accuracy: 1.0000 - val_loss: 1.0934 - val_accuracy: 0.8772\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.5120e-04 - accuracy: 1.0000 - val_loss: 1.1033 - val_accuracy: 0.8772\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.6353e-04 - accuracy: 1.0000 - val_loss: 1.1145 - val_accuracy: 0.8772\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.5541e-04 - accuracy: 1.0000 - val_loss: 1.1138 - val_accuracy: 0.8772\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.6501e-04 - accuracy: 1.0000 - val_loss: 1.1290 - val_accuracy: 0.8772\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.3266e-04 - accuracy: 1.0000 - val_loss: 1.1296 - val_accuracy: 0.8772\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.6472e-04 - accuracy: 1.0000 - val_loss: 1.1179 - val_accuracy: 0.8772\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.1559e-04 - accuracy: 1.0000 - val_loss: 1.1420 - val_accuracy: 0.8772\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 5.5281e-04 - accuracy: 1.0000 - val_loss: 1.1522 - val_accuracy: 0.8772\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.9620e-04 - accuracy: 1.0000 - val_loss: 1.1402 - val_accuracy: 0.8772\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.8234e-04 - accuracy: 1.0000 - val_loss: 1.1236 - val_accuracy: 0.8772\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.9226e-04 - accuracy: 1.0000 - val_loss: 1.1284 - val_accuracy: 0.8772\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.7142e-04 - accuracy: 1.0000 - val_loss: 1.1410 - val_accuracy: 0.8772\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.5746e-04 - accuracy: 1.0000 - val_loss: 1.1526 - val_accuracy: 0.8772\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.6084e-04 - accuracy: 1.0000 - val_loss: 1.1589 - val_accuracy: 0.8772\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.4288e-04 - accuracy: 1.0000 - val_loss: 1.1664 - val_accuracy: 0.8772\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.3968e-04 - accuracy: 1.0000 - val_loss: 1.1721 - val_accuracy: 0.8772\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.3695e-04 - accuracy: 1.0000 - val_loss: 1.1708 - val_accuracy: 0.8772\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.1969e-04 - accuracy: 1.0000 - val_loss: 1.1773 - val_accuracy: 0.8772\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.2077e-04 - accuracy: 1.0000 - val_loss: 1.1771 - val_accuracy: 0.8772\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 4.1259e-04 - accuracy: 1.0000 - val_loss: 1.1719 - val_accuracy: 0.8772\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.0978e-04 - accuracy: 1.0000 - val_loss: 1.1692 - val_accuracy: 0.8772\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.9183e-04 - accuracy: 1.0000 - val_loss: 1.1804 - val_accuracy: 0.8772\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.9168e-04 - accuracy: 1.0000 - val_loss: 1.1880 - val_accuracy: 0.8772\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.0623e-04 - accuracy: 1.0000 - val_loss: 1.1869 - val_accuracy: 0.8772\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.8610e-04 - accuracy: 1.0000 - val_loss: 1.2027 - val_accuracy: 0.8772\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.1010e-04 - accuracy: 1.0000 - val_loss: 1.2098 - val_accuracy: 0.8772\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 3.9501e-04 - accuracy: 1.0000 - val_loss: 1.1828 - val_accuracy: 0.8772\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.8342e-04 - accuracy: 1.0000 - val_loss: 1.1887 - val_accuracy: 0.8772\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 3.6604e-04 - accuracy: 1.0000 - val_loss: 1.2201 - val_accuracy: 0.8772\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.8768e-04 - accuracy: 1.0000 - val_loss: 1.2297 - val_accuracy: 0.8772\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.7555e-04 - accuracy: 1.0000 - val_loss: 1.2123 - val_accuracy: 0.8772\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.1799e-04 - accuracy: 1.0000 - val_loss: 1.1946 - val_accuracy: 0.8772\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 3.3769e-04 - accuracy: 1.0000 - val_loss: 1.1867 - val_accuracy: 0.8772\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.6720e-04 - accuracy: 1.0000 - val_loss: 1.2044 - val_accuracy: 0.8772\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.3338e-04 - accuracy: 1.0000 - val_loss: 1.2164 - val_accuracy: 0.8772\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.2946e-04 - accuracy: 1.0000 - val_loss: 1.2268 - val_accuracy: 0.8772\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.2342e-04 - accuracy: 1.0000 - val_loss: 1.2304 - val_accuracy: 0.8772\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.2180e-04 - accuracy: 1.0000 - val_loss: 1.2317 - val_accuracy: 0.8772\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.0863e-04 - accuracy: 1.0000 - val_loss: 1.2251 - val_accuracy: 0.8772\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.0301e-04 - accuracy: 1.0000 - val_loss: 1.2220 - val_accuracy: 0.8772\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.9994e-04 - accuracy: 1.0000 - val_loss: 1.2240 - val_accuracy: 0.8772\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.0927e-04 - accuracy: 1.0000 - val_loss: 1.2378 - val_accuracy: 0.8772\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.9607e-04 - accuracy: 1.0000 - val_loss: 1.2367 - val_accuracy: 0.8772\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.9626e-04 - accuracy: 1.0000 - val_loss: 1.2364 - val_accuracy: 0.8772\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.9523e-04 - accuracy: 1.0000 - val_loss: 1.2474 - val_accuracy: 0.8772\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.8829e-04 - accuracy: 1.0000 - val_loss: 1.2448 - val_accuracy: 0.8772\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.8022e-04 - accuracy: 1.0000 - val_loss: 1.2501 - val_accuracy: 0.8772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd6d6237860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sRBwGzsgGvx"
      },
      "source": [
        "Define the RMSprop optimizer with a learning rate of 0.05."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odyJo-kugGvy"
      },
      "source": [
        "# Answer below:\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim = 10 , activation= 'relu'))\n",
        "model.add(Dense( 64, activation= 'relu'))\n",
        "model.add(Dense(32, activation= 'relu'))\n",
        "model.add(Dense(32, activation= 'relu'))\n",
        "model.add(Dense(1, activation= 'sigmoid'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSthrUY00hf2"
      },
      "source": [
        "RMS = RMSprop(learning_rate= .05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7GaEJGugGvz"
      },
      "source": [
        "Compile and fit the model using the optimizer defined above. What do you notice about the accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yCh6LuV1R1i"
      },
      "source": [
        "model.compile(optimizer=RMS, loss= 'binary_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "477zsxjvgGv0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a5c3ebb0-131f-4252-d2b9-356641ae18d6"
      },
      "source": [
        "# Answer below:\n",
        "model.fit(X_train_Scaled, y_train, batch_size=100, epochs= 200, verbose= 1, validation_data=(X_test_Scaled, y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 151.3317 - accuracy: 0.7033 - val_loss: 18.7786 - val_accuracy: 0.4561\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 3.6578 - accuracy: 0.7890 - val_loss: 0.2770 - val_accuracy: 0.9474\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1595 - accuracy: 0.9516 - val_loss: 0.2160 - val_accuracy: 0.9386\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1339 - accuracy: 0.9451 - val_loss: 0.1638 - val_accuracy: 0.9474\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1236 - accuracy: 0.9451 - val_loss: 0.1779 - val_accuracy: 0.9211\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1133 - accuracy: 0.9516 - val_loss: 0.2105 - val_accuracy: 0.9211\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1122 - accuracy: 0.9516 - val_loss: 0.2673 - val_accuracy: 0.9123\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1075 - accuracy: 0.9582 - val_loss: 0.2558 - val_accuracy: 0.8772\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1300 - accuracy: 0.9582 - val_loss: 0.2532 - val_accuracy: 0.9123\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1818 - accuracy: 0.9648 - val_loss: 0.1885 - val_accuracy: 0.9123\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1020 - accuracy: 0.9626 - val_loss: 0.2604 - val_accuracy: 0.8772\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0897 - accuracy: 0.9648 - val_loss: 0.4227 - val_accuracy: 0.9123\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1085 - accuracy: 0.9604 - val_loss: 1.0393 - val_accuracy: 0.9298\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1991 - accuracy: 0.9407 - val_loss: 0.1910 - val_accuracy: 0.9211\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1151 - accuracy: 0.9473 - val_loss: 0.1716 - val_accuracy: 0.9123\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0944 - accuracy: 0.9604 - val_loss: 0.2882 - val_accuracy: 0.9123\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1671 - accuracy: 0.9341 - val_loss: 2.3766 - val_accuracy: 0.8684\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.9451 - val_loss: 0.1970 - val_accuracy: 0.8860\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1324 - accuracy: 0.9516 - val_loss: 0.1455 - val_accuracy: 0.9035\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0898 - accuracy: 0.9626 - val_loss: 0.1779 - val_accuracy: 0.8860\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1560 - accuracy: 0.9363 - val_loss: 0.1333 - val_accuracy: 0.9035\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0901 - accuracy: 0.9626 - val_loss: 0.1281 - val_accuracy: 0.9298\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2246 - accuracy: 0.9407 - val_loss: 0.2471 - val_accuracy: 0.9035\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1091 - accuracy: 0.9582 - val_loss: 0.2442 - val_accuracy: 0.8947\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0982 - accuracy: 0.9648 - val_loss: 0.2728 - val_accuracy: 0.8772\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1789 - accuracy: 0.9407 - val_loss: 0.3078 - val_accuracy: 0.9123\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0819 - accuracy: 0.9648 - val_loss: 0.4626 - val_accuracy: 0.9123\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1445 - accuracy: 0.9670 - val_loss: 0.5861 - val_accuracy: 0.9298\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1599 - accuracy: 0.9385 - val_loss: 0.2521 - val_accuracy: 0.9298\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1361 - accuracy: 0.9604 - val_loss: 0.2262 - val_accuracy: 0.8947\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9692 - val_loss: 0.3175 - val_accuracy: 0.9123\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0851 - accuracy: 0.9714 - val_loss: 0.4519 - val_accuracy: 0.9123\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1294 - accuracy: 0.9582 - val_loss: 0.3071 - val_accuracy: 0.9123\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0710 - accuracy: 0.9780 - val_loss: 0.4072 - val_accuracy: 0.9298\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0861 - accuracy: 0.9714 - val_loss: 0.5259 - val_accuracy: 0.8947\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4939 - accuracy: 0.9516 - val_loss: 0.2720 - val_accuracy: 0.9123\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9714 - val_loss: 0.2165 - val_accuracy: 0.8772\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0610 - accuracy: 0.9780 - val_loss: 0.3175 - val_accuracy: 0.9298\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9626 - val_loss: 0.9629 - val_accuracy: 0.9035\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0954 - accuracy: 0.9714 - val_loss: 0.4576 - val_accuracy: 0.9123\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9758 - val_loss: 0.6996 - val_accuracy: 0.8860\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9780 - val_loss: 0.8097 - val_accuracy: 0.9035\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1460 - accuracy: 0.9692 - val_loss: 0.5214 - val_accuracy: 0.8947\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2121 - accuracy: 0.9604 - val_loss: 0.1611 - val_accuracy: 0.9211\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1010 - accuracy: 0.9802 - val_loss: 3.0506 - val_accuracy: 0.5439\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5834 - accuracy: 0.8901 - val_loss: 0.9007 - val_accuracy: 0.8596\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2117 - accuracy: 0.9626 - val_loss: 0.1407 - val_accuracy: 0.9298\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.9736 - val_loss: 0.2278 - val_accuracy: 0.9298\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0585 - accuracy: 0.9692 - val_loss: 0.2092 - val_accuracy: 0.9386\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1012 - accuracy: 0.9736 - val_loss: 0.2213 - val_accuracy: 0.9211\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0552 - accuracy: 0.9780 - val_loss: 0.2729 - val_accuracy: 0.9298\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0460 - accuracy: 0.9780 - val_loss: 0.3792 - val_accuracy: 0.8947\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9758 - val_loss: 0.4732 - val_accuracy: 0.9474\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1751 - accuracy: 0.9538 - val_loss: 0.3196 - val_accuracy: 0.9123\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.9758 - val_loss: 0.3419 - val_accuracy: 0.9298\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9736 - val_loss: 0.5856 - val_accuracy: 0.9386\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.9824 - val_loss: 0.5012 - val_accuracy: 0.9298\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 0.9824 - val_loss: 1.0108 - val_accuracy: 0.9123\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0871 - accuracy: 0.9692 - val_loss: 0.2232 - val_accuracy: 0.8947\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.9692 - val_loss: 0.3089 - val_accuracy: 0.8947\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0479 - accuracy: 0.9736 - val_loss: 0.4472 - val_accuracy: 0.9298\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1230 - accuracy: 0.9626 - val_loss: 0.2370 - val_accuracy: 0.8860\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1260 - accuracy: 0.9648 - val_loss: 0.1571 - val_accuracy: 0.9123\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1203 - accuracy: 0.9758 - val_loss: 0.4237 - val_accuracy: 0.8947\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0740 - accuracy: 0.9714 - val_loss: 0.3050 - val_accuracy: 0.8947\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0562 - accuracy: 0.9714 - val_loss: 0.4169 - val_accuracy: 0.8947\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.9626 - val_loss: 0.4453 - val_accuracy: 0.8947\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9648 - val_loss: 0.4578 - val_accuracy: 0.8947\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.9802 - val_loss: 0.4888 - val_accuracy: 0.9035\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0475 - accuracy: 0.9736 - val_loss: 0.5630 - val_accuracy: 0.9123\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9714 - val_loss: 0.3986 - val_accuracy: 0.9298\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1482 - accuracy: 0.9582 - val_loss: 0.6612 - val_accuracy: 0.9035\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1329 - accuracy: 0.9560 - val_loss: 0.7727 - val_accuracy: 0.8860\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1099 - accuracy: 0.9626 - val_loss: 0.6253 - val_accuracy: 0.9035\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.9736 - val_loss: 0.4966 - val_accuracy: 0.9035\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9758 - val_loss: 0.3892 - val_accuracy: 0.8947\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0337 - accuracy: 0.9802 - val_loss: 0.7808 - val_accuracy: 0.8860\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9802 - val_loss: 0.7087 - val_accuracy: 0.8947\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0384 - accuracy: 0.9802 - val_loss: 0.4923 - val_accuracy: 0.8947\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9846 - val_loss: 0.2801 - val_accuracy: 0.9211\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0775 - accuracy: 0.9692 - val_loss: 0.1447 - val_accuracy: 0.9211\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9736 - val_loss: 0.4933 - val_accuracy: 0.9211\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0939 - accuracy: 0.9626 - val_loss: 0.3559 - val_accuracy: 0.9211\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.9714 - val_loss: 0.2702 - val_accuracy: 0.9123\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0410 - accuracy: 0.9780 - val_loss: 0.6454 - val_accuracy: 0.8947\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.9670 - val_loss: 0.5859 - val_accuracy: 0.9123\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0381 - accuracy: 0.9846 - val_loss: 0.4265 - val_accuracy: 0.9123\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 0.9868 - val_loss: 0.1924 - val_accuracy: 0.9211\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0486 - accuracy: 0.9868 - val_loss: 0.2924 - val_accuracy: 0.9298\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6370 - accuracy: 0.9385 - val_loss: 0.7789 - val_accuracy: 0.9386\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.9758 - val_loss: 1.0467 - val_accuracy: 0.9386\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9802 - val_loss: 1.0161 - val_accuracy: 0.9386\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0375 - accuracy: 0.9824 - val_loss: 0.3862 - val_accuracy: 0.9561\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0349 - accuracy: 0.9824 - val_loss: 0.7259 - val_accuracy: 0.9123\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.9758 - val_loss: 0.3506 - val_accuracy: 0.9386\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0726 - accuracy: 0.9736 - val_loss: 0.7009 - val_accuracy: 0.9211\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0270 - accuracy: 0.9846 - val_loss: 0.8859 - val_accuracy: 0.9386\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0299 - accuracy: 0.9846 - val_loss: 0.8039 - val_accuracy: 0.9298\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - accuracy: 0.9868 - val_loss: 1.0049 - val_accuracy: 0.9123\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0230 - accuracy: 0.9868 - val_loss: 0.9179 - val_accuracy: 0.9035\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0279 - accuracy: 0.9868 - val_loss: 1.1386 - val_accuracy: 0.9035\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9868 - val_loss: 1.0099 - val_accuracy: 0.8947\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1391 - accuracy: 0.9780 - val_loss: 0.6072 - val_accuracy: 0.8772\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0647 - accuracy: 0.9670 - val_loss: 0.6614 - val_accuracy: 0.9298\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 0.9824 - val_loss: 0.3358 - val_accuracy: 0.9211\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0714 - accuracy: 0.9758 - val_loss: 0.3856 - val_accuracy: 0.9035\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2990 - accuracy: 0.8615 - val_loss: 0.8667 - val_accuracy: 0.9298\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0334 - accuracy: 0.9297 - val_loss: 0.4448 - val_accuracy: 0.8509\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9670 - val_loss: 0.3913 - val_accuracy: 0.8772\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0739 - accuracy: 0.9714 - val_loss: 0.3298 - val_accuracy: 0.8772\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9736 - val_loss: 0.4436 - val_accuracy: 0.9123\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0486 - accuracy: 0.9736 - val_loss: 0.4523 - val_accuracy: 0.8947\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0359 - accuracy: 0.9780 - val_loss: 0.6733 - val_accuracy: 0.9035\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 0.9736 - val_loss: 0.5168 - val_accuracy: 0.8772\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0331 - accuracy: 0.9802 - val_loss: 0.6896 - val_accuracy: 0.9035\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1118 - accuracy: 0.9736 - val_loss: 0.5175 - val_accuracy: 0.8947\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0489 - accuracy: 0.9802 - val_loss: 1.2757 - val_accuracy: 0.8860\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9780 - val_loss: 0.9770 - val_accuracy: 0.8860\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0256 - accuracy: 0.9824 - val_loss: 0.9429 - val_accuracy: 0.8772\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 0.9868 - val_loss: 1.5202 - val_accuracy: 0.8772\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9758 - val_loss: 1.1427 - val_accuracy: 0.8684\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 0.9824 - val_loss: 1.2816 - val_accuracy: 0.8684\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9846 - val_loss: 1.0525 - val_accuracy: 0.8772\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0212 - accuracy: 0.9868 - val_loss: 1.0662 - val_accuracy: 0.8772\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0195 - accuracy: 0.9868 - val_loss: 0.9670 - val_accuracy: 0.8772\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9868 - val_loss: 1.0704 - val_accuracy: 0.8772\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1183 - accuracy: 0.9868 - val_loss: 1.7501 - val_accuracy: 0.8772\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1739 - accuracy: 0.9824 - val_loss: 0.2685 - val_accuracy: 0.9123\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9758 - val_loss: 0.4223 - val_accuracy: 0.9298\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0360 - accuracy: 0.9846 - val_loss: 0.4867 - val_accuracy: 0.9211\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0250 - accuracy: 0.9868 - val_loss: 0.5935 - val_accuracy: 0.8947\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.9736 - val_loss: 0.4603 - val_accuracy: 0.9211\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9736 - val_loss: 0.2035 - val_accuracy: 0.8947\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0477 - accuracy: 0.9846 - val_loss: 0.6915 - val_accuracy: 0.9211\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0228 - accuracy: 0.9846 - val_loss: 0.6833 - val_accuracy: 0.9211\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3638 - accuracy: 0.9670 - val_loss: 1.6800 - val_accuracy: 0.6754\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1511 - accuracy: 0.9451 - val_loss: 0.1821 - val_accuracy: 0.9123\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0431 - accuracy: 0.9758 - val_loss: 0.4877 - val_accuracy: 0.9211\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9780 - val_loss: 0.8879 - val_accuracy: 0.9211\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0340 - accuracy: 0.9780 - val_loss: 0.6441 - val_accuracy: 0.9211\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.9780 - val_loss: 1.4865 - val_accuracy: 0.9211\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0569 - accuracy: 0.9780 - val_loss: 1.9166 - val_accuracy: 0.9123\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.9582 - val_loss: 0.3978 - val_accuracy: 0.9035\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0473 - accuracy: 0.9714 - val_loss: 0.5644 - val_accuracy: 0.9035\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0492 - accuracy: 0.9736 - val_loss: 0.3713 - val_accuracy: 0.9386\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0456 - accuracy: 0.9868 - val_loss: 0.5852 - val_accuracy: 0.9211\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0311 - accuracy: 0.9802 - val_loss: 0.1779 - val_accuracy: 0.9474\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0480 - accuracy: 0.9802 - val_loss: 0.4895 - val_accuracy: 0.9035\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0327 - accuracy: 0.9868 - val_loss: 0.5236 - val_accuracy: 0.9123\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 0.9824 - val_loss: 0.9873 - val_accuracy: 0.9035\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9868 - val_loss: 0.6347 - val_accuracy: 0.9035\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0219 - accuracy: 0.9868 - val_loss: 1.4497 - val_accuracy: 0.8947\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9868 - val_loss: 2.8167 - val_accuracy: 0.4474\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9300 - accuracy: 0.7934 - val_loss: 0.1878 - val_accuracy: 0.9211\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9824 - val_loss: 0.2897 - val_accuracy: 0.9211\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0306 - accuracy: 0.9846 - val_loss: 0.2545 - val_accuracy: 0.9298\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 0.9802 - val_loss: 0.4588 - val_accuracy: 0.9035\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 0.9890 - val_loss: 0.4201 - val_accuracy: 0.9035\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9890 - val_loss: 0.6126 - val_accuracy: 0.8947\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9890 - val_loss: 0.7837 - val_accuracy: 0.8947\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0190 - accuracy: 0.9868 - val_loss: 0.7725 - val_accuracy: 0.9035\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0777 - accuracy: 0.9780 - val_loss: 0.3981 - val_accuracy: 0.9298\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9959 - accuracy: 0.8791 - val_loss: 0.2956 - val_accuracy: 0.9123\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0813 - accuracy: 0.9714 - val_loss: 0.3935 - val_accuracy: 0.8860\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0560 - accuracy: 0.9714 - val_loss: 0.5353 - val_accuracy: 0.8947\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9802 - val_loss: 0.4512 - val_accuracy: 0.9035\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0202 - accuracy: 0.9868 - val_loss: 0.9082 - val_accuracy: 0.9123\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.9868 - val_loss: 2.5545 - val_accuracy: 0.8947\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0311 - accuracy: 0.9824 - val_loss: 1.9610 - val_accuracy: 0.9123\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.8440 - val_loss: 0.3871 - val_accuracy: 0.9123\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3705 - accuracy: 0.9824 - val_loss: 0.3531 - val_accuracy: 0.8947\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2919 - accuracy: 0.9802 - val_loss: 0.3078 - val_accuracy: 0.9123\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2441 - accuracy: 0.9802 - val_loss: 0.2592 - val_accuracy: 0.9298\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2062 - accuracy: 0.9846 - val_loss: 0.2433 - val_accuracy: 0.9298\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1789 - accuracy: 0.9846 - val_loss: 0.2322 - val_accuracy: 0.9298\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1571 - accuracy: 0.9846 - val_loss: 0.2251 - val_accuracy: 0.9298\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1398 - accuracy: 0.9846 - val_loss: 0.2208 - val_accuracy: 0.9298\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1258 - accuracy: 0.9846 - val_loss: 0.2189 - val_accuracy: 0.9298\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9846 - val_loss: 0.2188 - val_accuracy: 0.9298\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1051 - accuracy: 0.9846 - val_loss: 0.2202 - val_accuracy: 0.9298\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9846 - val_loss: 0.2230 - val_accuracy: 0.9298\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0914 - accuracy: 0.9846 - val_loss: 0.2266 - val_accuracy: 0.9298\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0867 - accuracy: 0.9846 - val_loss: 0.2311 - val_accuracy: 0.9298\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.9802 - val_loss: 1.4990 - val_accuracy: 0.8246\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.9385 - val_loss: 0.2341 - val_accuracy: 0.9298\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1523 - accuracy: 0.9604 - val_loss: 0.2347 - val_accuracy: 0.9298\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1458 - accuracy: 0.9626 - val_loss: 0.2355 - val_accuracy: 0.9298\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1388 - accuracy: 0.9648 - val_loss: 0.2362 - val_accuracy: 0.9298\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1387 - accuracy: 0.9648 - val_loss: 0.2354 - val_accuracy: 0.9298\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1387 - accuracy: 0.9648 - val_loss: 0.2372 - val_accuracy: 0.9298\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1389 - accuracy: 0.9648 - val_loss: 0.2363 - val_accuracy: 0.9298\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1390 - accuracy: 0.9648 - val_loss: 0.2352 - val_accuracy: 0.9298\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1388 - accuracy: 0.9648 - val_loss: 0.2347 - val_accuracy: 0.9298\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1390 - accuracy: 0.9648 - val_loss: 0.2349 - val_accuracy: 0.9298\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1393 - accuracy: 0.9648 - val_loss: 0.2362 - val_accuracy: 0.9298\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1390 - accuracy: 0.9648 - val_loss: 0.2374 - val_accuracy: 0.9298\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1388 - accuracy: 0.9648 - val_loss: 0.2388 - val_accuracy: 0.9298\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1392 - accuracy: 0.9648 - val_loss: 0.2393 - val_accuracy: 0.9298\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1390 - accuracy: 0.9648 - val_loss: 0.2381 - val_accuracy: 0.9298\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1388 - accuracy: 0.9648 - val_loss: 0.2360 - val_accuracy: 0.9298\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd6d40c2630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3KhWb3igGv1"
      },
      "source": [
        "Define the Adam optimizer with learning rate 0.01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewtmWJI3gGv1"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "# Answer below:\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim = 10 , activation= 'relu'))\n",
        "model.add(Dense( 64, activation= 'relu'))\n",
        "model.add(Dense(32, activation= 'relu'))\n",
        "model.add(Dense(32, activation= 'relu'))\n",
        "model.add(Dense(1, activation= 'sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv9ejwz233s3"
      },
      "source": [
        "adam = Adam(learning_rate= .01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnxqbb7CgGv3"
      },
      "source": [
        "Compile and fit the model using the optimizer defined above. How does the peformance differ with this optimizer?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG9-9Nk4gGv3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4b3db1d-9563-4438-9ada-25419b3efa27"
      },
      "source": [
        "# Answer below:\n",
        "model.compile(optimizer=adam, loss= 'binary_crossentropy', metrics= ['accuracy'])\n",
        "model.fit(X_train_Scaled, y_train, batch_size=100, epochs= 200, verbose= 1, validation_data=(X_test_Scaled, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.4564 - accuracy: 0.7648 - val_loss: 0.2305 - val_accuracy: 0.9123\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1973 - accuracy: 0.9275 - val_loss: 0.1947 - val_accuracy: 0.9386\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1601 - accuracy: 0.9495 - val_loss: 0.0968 - val_accuracy: 0.9561\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1584 - accuracy: 0.9473 - val_loss: 0.1888 - val_accuracy: 0.9035\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.9604 - val_loss: 0.2354 - val_accuracy: 0.9123\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.9582 - val_loss: 0.1497 - val_accuracy: 0.9474\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0991 - accuracy: 0.9538 - val_loss: 0.1345 - val_accuracy: 0.9386\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.9626 - val_loss: 0.1666 - val_accuracy: 0.9298\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0820 - accuracy: 0.9648 - val_loss: 0.1667 - val_accuracy: 0.9298\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0776 - accuracy: 0.9692 - val_loss: 0.1885 - val_accuracy: 0.9123\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.9714 - val_loss: 0.2439 - val_accuracy: 0.9123\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.9714 - val_loss: 0.2314 - val_accuracy: 0.9123\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0641 - accuracy: 0.9736 - val_loss: 0.2410 - val_accuracy: 0.9123\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0585 - accuracy: 0.9780 - val_loss: 0.2557 - val_accuracy: 0.9123\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0498 - accuracy: 0.9758 - val_loss: 0.1611 - val_accuracy: 0.9386\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0587 - accuracy: 0.9802 - val_loss: 0.3104 - val_accuracy: 0.8772\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0527 - accuracy: 0.9824 - val_loss: 0.2472 - val_accuracy: 0.9123\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0528 - accuracy: 0.9824 - val_loss: 0.3407 - val_accuracy: 0.9211\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0578 - accuracy: 0.9802 - val_loss: 0.2624 - val_accuracy: 0.9211\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0548 - accuracy: 0.9758 - val_loss: 0.2939 - val_accuracy: 0.9123\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0415 - accuracy: 0.9824 - val_loss: 0.2630 - val_accuracy: 0.8947\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0399 - accuracy: 0.9846 - val_loss: 0.2554 - val_accuracy: 0.9123\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0293 - accuracy: 0.9890 - val_loss: 0.4092 - val_accuracy: 0.8947\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.9890 - val_loss: 0.4423 - val_accuracy: 0.9035\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0218 - accuracy: 0.9912 - val_loss: 0.4728 - val_accuracy: 0.9123\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0295 - accuracy: 0.9890 - val_loss: 0.4557 - val_accuracy: 0.9123\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0280 - accuracy: 0.9912 - val_loss: 0.5943 - val_accuracy: 0.8860\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9846 - val_loss: 0.7032 - val_accuracy: 0.8860\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0492 - accuracy: 0.9802 - val_loss: 0.4036 - val_accuracy: 0.9298\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9824 - val_loss: 0.6294 - val_accuracy: 0.8860\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 0.9846 - val_loss: 0.5921 - val_accuracy: 0.8860\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.9824 - val_loss: 0.5209 - val_accuracy: 0.8947\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 0.9802 - val_loss: 0.4103 - val_accuracy: 0.9035\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 0.9846 - val_loss: 0.3389 - val_accuracy: 0.9211\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0425 - accuracy: 0.9802 - val_loss: 0.3323 - val_accuracy: 0.9035\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0370 - accuracy: 0.9868 - val_loss: 0.3206 - val_accuracy: 0.9035\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 0.9890 - val_loss: 0.5058 - val_accuracy: 0.9035\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9934 - val_loss: 0.3836 - val_accuracy: 0.9298\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0162 - accuracy: 0.9956 - val_loss: 0.5300 - val_accuracy: 0.9035\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 0.9934 - val_loss: 0.5002 - val_accuracy: 0.9035\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.9978 - val_loss: 0.6025 - val_accuracy: 0.9035\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0100 - accuracy: 0.9956 - val_loss: 0.7335 - val_accuracy: 0.9035\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9956 - val_loss: 0.6738 - val_accuracy: 0.9035\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.9956 - val_loss: 0.7148 - val_accuracy: 0.9035\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.9080 - val_accuracy: 0.8947\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.7282 - val_accuracy: 0.9035\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0137 - accuracy: 0.9934 - val_loss: 0.5464 - val_accuracy: 0.9211\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0164 - accuracy: 0.9912 - val_loss: 0.7118 - val_accuracy: 0.9123\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0247 - accuracy: 0.9912 - val_loss: 0.7167 - val_accuracy: 0.9035\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0165 - accuracy: 0.9890 - val_loss: 0.7397 - val_accuracy: 0.9035\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0289 - accuracy: 0.9890 - val_loss: 0.6794 - val_accuracy: 0.9123\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 0.9890 - val_loss: 0.7526 - val_accuracy: 0.8947\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.5772 - val_accuracy: 0.9123\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9956 - val_loss: 0.8505 - val_accuracy: 0.9123\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 0.9912 - val_loss: 0.8986 - val_accuracy: 0.8860\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0290 - accuracy: 0.9912 - val_loss: 1.0400 - val_accuracy: 0.8860\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0467 - accuracy: 0.9890 - val_loss: 0.8402 - val_accuracy: 0.8947\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0225 - accuracy: 0.9890 - val_loss: 0.7644 - val_accuracy: 0.8947\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9978 - val_loss: 0.6889 - val_accuracy: 0.8947\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.7394 - val_accuracy: 0.9035\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0127 - accuracy: 0.9934 - val_loss: 0.7747 - val_accuracy: 0.9035\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - accuracy: 0.9956 - val_loss: 0.7214 - val_accuracy: 0.9035\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.8150 - val_accuracy: 0.9035\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0101 - accuracy: 0.9934 - val_loss: 0.7245 - val_accuracy: 0.9123\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0162 - accuracy: 0.9956 - val_loss: 0.8180 - val_accuracy: 0.9123\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9934 - val_loss: 0.9571 - val_accuracy: 0.9035\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9956 - val_loss: 0.6012 - val_accuracy: 0.9123\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.9956 - val_loss: 0.5139 - val_accuracy: 0.9211\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9956 - val_loss: 0.5152 - val_accuracy: 0.9211\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.5616 - val_accuracy: 0.9211\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.6365 - val_accuracy: 0.9211\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.9978 - val_loss: 0.7103 - val_accuracy: 0.9211\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7639 - val_accuracy: 0.9211\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7867 - val_accuracy: 0.9211\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.9978 - val_loss: 0.8658 - val_accuracy: 0.9211\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 0.9978 - val_loss: 0.8802 - val_accuracy: 0.9211\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9443 - val_accuracy: 0.9211\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.9978 - val_loss: 0.9547 - val_accuracy: 0.9211\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.9978 - val_loss: 0.9364 - val_accuracy: 0.9211\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 0.9978 - val_loss: 1.0524 - val_accuracy: 0.9123\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9978 - val_loss: 1.0122 - val_accuracy: 0.9211\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0050 - val_accuracy: 0.9211\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1182 - val_accuracy: 0.9211\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1110 - val_accuracy: 0.9211\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.1216 - val_accuracy: 0.9211\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 9.1644e-04 - accuracy: 1.0000 - val_loss: 1.1642 - val_accuracy: 0.9211\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8.8813e-04 - accuracy: 1.0000 - val_loss: 1.1923 - val_accuracy: 0.9211\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 9.3325e-04 - accuracy: 1.0000 - val_loss: 1.2243 - val_accuracy: 0.9211\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 6.6162e-04 - accuracy: 1.0000 - val_loss: 1.2170 - val_accuracy: 0.9211\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 0.9978 - val_loss: 1.2693 - val_accuracy: 0.9123\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3726 - val_accuracy: 0.9123\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 1.2205 - val_accuracy: 0.9211\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9978 - val_loss: 1.2116 - val_accuracy: 0.9211\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3111 - val_accuracy: 0.9123\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 0.9978 - val_loss: 1.2551 - val_accuracy: 0.9211\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.1846 - val_accuracy: 0.9211\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.9978 - val_loss: 1.2872 - val_accuracy: 0.9211\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.7457e-04 - accuracy: 1.0000 - val_loss: 1.4085 - val_accuracy: 0.9123\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.9956 - val_loss: 1.2090 - val_accuracy: 0.9211\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1788 - val_accuracy: 0.9211\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.9978 - val_loss: 1.3328 - val_accuracy: 0.9211\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 0.9978 - val_loss: 1.3315 - val_accuracy: 0.9211\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0269 - accuracy: 0.9912 - val_loss: 1.1325 - val_accuracy: 0.9211\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1103 - accuracy: 0.9868 - val_loss: 1.0429 - val_accuracy: 0.9035\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1218 - accuracy: 0.9736 - val_loss: 0.4977 - val_accuracy: 0.8772\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1491 - accuracy: 0.9560 - val_loss: 0.1862 - val_accuracy: 0.9123\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.9736 - val_loss: 0.3507 - val_accuracy: 0.9211\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.9714 - val_loss: 0.2260 - val_accuracy: 0.9211\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0704 - accuracy: 0.9714 - val_loss: 0.1394 - val_accuracy: 0.9211\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.9736 - val_loss: 0.2570 - val_accuracy: 0.9211\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.9780 - val_loss: 0.3401 - val_accuracy: 0.9211\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0466 - accuracy: 0.9802 - val_loss: 0.1812 - val_accuracy: 0.9211\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0464 - accuracy: 0.9780 - val_loss: 0.1989 - val_accuracy: 0.9211\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0349 - accuracy: 0.9868 - val_loss: 0.2791 - val_accuracy: 0.9123\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 0.9824 - val_loss: 0.3225 - val_accuracy: 0.9123\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0249 - accuracy: 0.9868 - val_loss: 0.3044 - val_accuracy: 0.9123\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9868 - val_loss: 0.3729 - val_accuracy: 0.9123\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9868 - val_loss: 0.4844 - val_accuracy: 0.9035\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0160 - accuracy: 0.9868 - val_loss: 0.4909 - val_accuracy: 0.9035\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.4990 - val_accuracy: 0.9035\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9956 - val_loss: 0.5818 - val_accuracy: 0.9035\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.6501 - val_accuracy: 0.9035\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.6895 - val_accuracy: 0.9035\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7826 - val_accuracy: 0.9035\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9978 - val_loss: 0.8759 - val_accuracy: 0.9035\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9978 - val_loss: 0.8769 - val_accuracy: 0.9035\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 1.1628 - val_accuracy: 0.8860\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 0.9978 - val_loss: 1.0884 - val_accuracy: 0.8860\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 0.9978 - val_loss: 0.9509 - val_accuracy: 0.8947\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9956 - val_loss: 0.9156 - val_accuracy: 0.9035\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - accuracy: 0.9956 - val_loss: 0.9011 - val_accuracy: 0.9035\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.6717 - val_accuracy: 0.9035\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.5414 - val_accuracy: 0.9123\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.5960 - val_accuracy: 0.9123\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6904 - val_accuracy: 0.9123\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.9978 - val_loss: 0.7018 - val_accuracy: 0.9123\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.9978 - val_loss: 0.7394 - val_accuracy: 0.9035\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.9978 - val_loss: 0.8061 - val_accuracy: 0.8947\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 0.9978 - val_loss: 0.8740 - val_accuracy: 0.8947\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 0.9978 - val_loss: 0.9222 - val_accuracy: 0.8947\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 0.9978 - val_loss: 0.9720 - val_accuracy: 0.8947\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 0.9978 - val_loss: 0.9971 - val_accuracy: 0.8947\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 0.9978 - val_loss: 1.0197 - val_accuracy: 0.8947\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 0.9978 - val_loss: 1.0508 - val_accuracy: 0.8947\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 0.9978 - val_loss: 1.0663 - val_accuracy: 0.8947\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.0940 - val_accuracy: 0.8947\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1136 - val_accuracy: 0.8947\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.9978 - val_loss: 1.1381 - val_accuracy: 0.8947\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.1814 - val_accuracy: 0.8947\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2043 - val_accuracy: 0.8947\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 6.0389e-04 - accuracy: 1.0000 - val_loss: 1.2170 - val_accuracy: 0.8947\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 5.3205e-04 - accuracy: 1.0000 - val_loss: 1.2585 - val_accuracy: 0.8947\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.7794e-04 - accuracy: 1.0000 - val_loss: 1.2770 - val_accuracy: 0.8947\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.6574e-04 - accuracy: 1.0000 - val_loss: 1.2601 - val_accuracy: 0.8947\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.0023e-04 - accuracy: 1.0000 - val_loss: 1.2893 - val_accuracy: 0.8947\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.9837e-04 - accuracy: 1.0000 - val_loss: 1.3180 - val_accuracy: 0.8947\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.5354e-04 - accuracy: 1.0000 - val_loss: 1.3430 - val_accuracy: 0.8947\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.3667e-04 - accuracy: 1.0000 - val_loss: 1.3567 - val_accuracy: 0.8947\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.2154e-04 - accuracy: 1.0000 - val_loss: 1.3669 - val_accuracy: 0.8947\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0225e-04 - accuracy: 1.0000 - val_loss: 1.3763 - val_accuracy: 0.8947\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 9.2030e-05 - accuracy: 1.0000 - val_loss: 1.3854 - val_accuracy: 0.8947\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8.0156e-05 - accuracy: 1.0000 - val_loss: 1.3898 - val_accuracy: 0.8947\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7.4985e-05 - accuracy: 1.0000 - val_loss: 1.3944 - val_accuracy: 0.8947\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 6.9280e-05 - accuracy: 1.0000 - val_loss: 1.4029 - val_accuracy: 0.8947\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 6.2884e-05 - accuracy: 1.0000 - val_loss: 1.4082 - val_accuracy: 0.8947\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.8060e-05 - accuracy: 1.0000 - val_loss: 1.4151 - val_accuracy: 0.8947\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.6646e-05 - accuracy: 1.0000 - val_loss: 1.4252 - val_accuracy: 0.8947\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.1372e-05 - accuracy: 1.0000 - val_loss: 1.4312 - val_accuracy: 0.8947\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.8850e-05 - accuracy: 1.0000 - val_loss: 1.4381 - val_accuracy: 0.8947\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.5377e-05 - accuracy: 1.0000 - val_loss: 1.4435 - val_accuracy: 0.8947\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 4.2924e-05 - accuracy: 1.0000 - val_loss: 1.4517 - val_accuracy: 0.8947\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.1123e-05 - accuracy: 1.0000 - val_loss: 1.4583 - val_accuracy: 0.8947\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.9193e-05 - accuracy: 1.0000 - val_loss: 1.4626 - val_accuracy: 0.8947\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.8218e-05 - accuracy: 1.0000 - val_loss: 1.4702 - val_accuracy: 0.8947\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.5532e-05 - accuracy: 1.0000 - val_loss: 1.4745 - val_accuracy: 0.8947\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.3499e-05 - accuracy: 1.0000 - val_loss: 1.4753 - val_accuracy: 0.8947\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 3.2895e-05 - accuracy: 1.0000 - val_loss: 1.4811 - val_accuracy: 0.8947\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 3.1640e-05 - accuracy: 1.0000 - val_loss: 1.4893 - val_accuracy: 0.8947\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 2.9774e-05 - accuracy: 1.0000 - val_loss: 1.4938 - val_accuracy: 0.8947\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.8910e-05 - accuracy: 1.0000 - val_loss: 1.4960 - val_accuracy: 0.8947\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.7784e-05 - accuracy: 1.0000 - val_loss: 1.4990 - val_accuracy: 0.8947\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 2.6633e-05 - accuracy: 1.0000 - val_loss: 1.5074 - val_accuracy: 0.8947\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.6188e-05 - accuracy: 1.0000 - val_loss: 1.5144 - val_accuracy: 0.8947\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.4477e-05 - accuracy: 1.0000 - val_loss: 1.5169 - val_accuracy: 0.8947\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.3550e-05 - accuracy: 1.0000 - val_loss: 1.5195 - val_accuracy: 0.8947\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 2.2504e-05 - accuracy: 1.0000 - val_loss: 1.5224 - val_accuracy: 0.8947\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 2.1720e-05 - accuracy: 1.0000 - val_loss: 1.5253 - val_accuracy: 0.8947\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 2.0978e-05 - accuracy: 1.0000 - val_loss: 1.5282 - val_accuracy: 0.8947\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 2.0312e-05 - accuracy: 1.0000 - val_loss: 1.5324 - val_accuracy: 0.8947\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.9735e-05 - accuracy: 1.0000 - val_loss: 1.5364 - val_accuracy: 0.8947\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.9623e-05 - accuracy: 1.0000 - val_loss: 1.5378 - val_accuracy: 0.8947\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.8676e-05 - accuracy: 1.0000 - val_loss: 1.5437 - val_accuracy: 0.8947\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.8003e-05 - accuracy: 1.0000 - val_loss: 1.5484 - val_accuracy: 0.8947\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.7769e-05 - accuracy: 1.0000 - val_loss: 1.5533 - val_accuracy: 0.8947\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.7122e-05 - accuracy: 1.0000 - val_loss: 1.5556 - val_accuracy: 0.8947\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.6506e-05 - accuracy: 1.0000 - val_loss: 1.5603 - val_accuracy: 0.8947\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.6101e-05 - accuracy: 1.0000 - val_loss: 1.5628 - val_accuracy: 0.8947\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.5736e-05 - accuracy: 1.0000 - val_loss: 1.5653 - val_accuracy: 0.8947\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.5311e-05 - accuracy: 1.0000 - val_loss: 1.5680 - val_accuracy: 0.8947\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4846e-05 - accuracy: 1.0000 - val_loss: 1.5709 - val_accuracy: 0.8947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd6d4f82e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1opnI2qCgGv5"
      },
      "source": [
        "Now change the learning rate to 0.1 in your Adam optimizer and compare the results (both speed and accuracy)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIGTzU1DgGv6"
      },
      "source": [
        "# Answer below:\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim = 10 , activation= 'relu'))\n",
        "model.add(Dense( 64, activation= 'relu'))\n",
        "model.add(Dense(32, activation= 'relu'))\n",
        "model.add(Dense(32, activation= 'relu'))\n",
        "model.add(Dense(1, activation= 'sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e91KQiHqgGv7"
      },
      "source": [
        "adam = Adam(learning_rate= .1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPq-q5_j4eRi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d03da8b-520f-4ee5-ca4a-5f94d6304eda"
      },
      "source": [
        "model.compile(optimizer=adam, loss= 'binary_crossentropy', metrics= ['accuracy'])\n",
        "model.fit(X_train_Scaled, y_train, batch_size=100, epochs= 200, verbose= 1, validation_data=(X_test_Scaled, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 8.7619 - accuracy: 0.4967 - val_loss: 1.0194 - val_accuracy: 0.6316\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7056 - accuracy: 0.7912 - val_loss: 0.2563 - val_accuracy: 0.8860\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2225 - accuracy: 0.9231 - val_loss: 0.3763 - val_accuracy: 0.8421\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1930 - accuracy: 0.9231 - val_loss: 0.3831 - val_accuracy: 0.8772\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2969 - accuracy: 0.9297 - val_loss: 0.2707 - val_accuracy: 0.8947\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2375 - accuracy: 0.9275 - val_loss: 0.2058 - val_accuracy: 0.9123\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1390 - accuracy: 0.9429 - val_loss: 0.1616 - val_accuracy: 0.9123\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1491 - accuracy: 0.9385 - val_loss: 0.1434 - val_accuracy: 0.9298\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1306 - accuracy: 0.9473 - val_loss: 0.1978 - val_accuracy: 0.9123\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1360 - accuracy: 0.9451 - val_loss: 0.1605 - val_accuracy: 0.9123\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1246 - accuracy: 0.9495 - val_loss: 0.1443 - val_accuracy: 0.9211\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1267 - accuracy: 0.9429 - val_loss: 0.1409 - val_accuracy: 0.9211\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1209 - accuracy: 0.9451 - val_loss: 0.1298 - val_accuracy: 0.9211\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1157 - accuracy: 0.9473 - val_loss: 0.1325 - val_accuracy: 0.9211\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1111 - accuracy: 0.9516 - val_loss: 0.1248 - val_accuracy: 0.9211\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9495 - val_loss: 0.1367 - val_accuracy: 0.9211\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1092 - accuracy: 0.9516 - val_loss: 0.1628 - val_accuracy: 0.9211\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1152 - accuracy: 0.9451 - val_loss: 0.1730 - val_accuracy: 0.9211\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1108 - accuracy: 0.9495 - val_loss: 0.1587 - val_accuracy: 0.9035\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1046 - accuracy: 0.9473 - val_loss: 0.1531 - val_accuracy: 0.9211\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1025 - accuracy: 0.9516 - val_loss: 0.1223 - val_accuracy: 0.9211\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0986 - accuracy: 0.9516 - val_loss: 0.1250 - val_accuracy: 0.9211\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9516 - val_loss: 0.1330 - val_accuracy: 0.9298\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0952 - accuracy: 0.9516 - val_loss: 0.1302 - val_accuracy: 0.9298\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0923 - accuracy: 0.9516 - val_loss: 0.1187 - val_accuracy: 0.9298\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0903 - accuracy: 0.9560 - val_loss: 0.1413 - val_accuracy: 0.9123\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0892 - accuracy: 0.9582 - val_loss: 0.1864 - val_accuracy: 0.8947\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9538 - val_loss: 0.1414 - val_accuracy: 0.9035\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9516 - val_loss: 0.1629 - val_accuracy: 0.8947\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9516 - val_loss: 0.1313 - val_accuracy: 0.9211\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0827 - accuracy: 0.9582 - val_loss: 0.2314 - val_accuracy: 0.9123\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0802 - accuracy: 0.9626 - val_loss: 0.1613 - val_accuracy: 0.9035\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0862 - accuracy: 0.9626 - val_loss: 0.1304 - val_accuracy: 0.9123\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9604 - val_loss: 0.1760 - val_accuracy: 0.9035\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9582 - val_loss: 0.2532 - val_accuracy: 0.9035\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0738 - accuracy: 0.9692 - val_loss: 0.2749 - val_accuracy: 0.9298\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0737 - accuracy: 0.9648 - val_loss: 0.3598 - val_accuracy: 0.9123\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0774 - accuracy: 0.9648 - val_loss: 0.1879 - val_accuracy: 0.9123\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1025 - accuracy: 0.9670 - val_loss: 0.1771 - val_accuracy: 0.9211\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9560 - val_loss: 0.1514 - val_accuracy: 0.9298\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1204 - accuracy: 0.9451 - val_loss: 0.1362 - val_accuracy: 0.9298\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0805 - accuracy: 0.9648 - val_loss: 0.0955 - val_accuracy: 0.9474\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0856 - accuracy: 0.9604 - val_loss: 0.1518 - val_accuracy: 0.9298\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0777 - accuracy: 0.9604 - val_loss: 0.2279 - val_accuracy: 0.9035\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0784 - accuracy: 0.9648 - val_loss: 0.1844 - val_accuracy: 0.9211\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0724 - accuracy: 0.9758 - val_loss: 0.1722 - val_accuracy: 0.9211\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.9736 - val_loss: 0.2192 - val_accuracy: 0.9123\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9758 - val_loss: 0.2510 - val_accuracy: 0.9123\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9736 - val_loss: 0.2789 - val_accuracy: 0.9035\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0647 - accuracy: 0.9758 - val_loss: 0.3542 - val_accuracy: 0.9123\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.9780 - val_loss: 0.2177 - val_accuracy: 0.9123\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0599 - accuracy: 0.9780 - val_loss: 0.2972 - val_accuracy: 0.9123\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0645 - accuracy: 0.9714 - val_loss: 0.3214 - val_accuracy: 0.9211\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.9692 - val_loss: 0.2367 - val_accuracy: 0.9211\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0875 - accuracy: 0.9692 - val_loss: 0.2827 - val_accuracy: 0.9123\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1058 - accuracy: 0.9714 - val_loss: 0.2151 - val_accuracy: 0.9211\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0911 - accuracy: 0.9736 - val_loss: 0.1901 - val_accuracy: 0.9211\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1075 - accuracy: 0.9714 - val_loss: 0.2740 - val_accuracy: 0.9123\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0945 - accuracy: 0.9758 - val_loss: 0.2476 - val_accuracy: 0.8772\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1124 - accuracy: 0.9604 - val_loss: 0.2169 - val_accuracy: 0.8772\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1511 - accuracy: 0.9648 - val_loss: 0.2102 - val_accuracy: 0.9035\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1396 - accuracy: 0.9604 - val_loss: 0.1705 - val_accuracy: 0.9035\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0845 - accuracy: 0.9692 - val_loss: 0.2562 - val_accuracy: 0.9035\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0978 - accuracy: 0.9692 - val_loss: 0.2099 - val_accuracy: 0.9035\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1022 - accuracy: 0.9692 - val_loss: 0.1152 - val_accuracy: 0.9298\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0605 - accuracy: 0.9758 - val_loss: 0.1434 - val_accuracy: 0.9298\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0703 - accuracy: 0.9758 - val_loss: 0.2149 - val_accuracy: 0.9298\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.9758 - val_loss: 0.1826 - val_accuracy: 0.9211\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0550 - accuracy: 0.9802 - val_loss: 0.2266 - val_accuracy: 0.9211\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0433 - accuracy: 0.9802 - val_loss: 0.2933 - val_accuracy: 0.9035\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0418 - accuracy: 0.9846 - val_loss: 0.2933 - val_accuracy: 0.9123\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0400 - accuracy: 0.9802 - val_loss: 0.2988 - val_accuracy: 0.9123\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0371 - accuracy: 0.9868 - val_loss: 0.3811 - val_accuracy: 0.9123\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 0.9802 - val_loss: 0.3991 - val_accuracy: 0.9211\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9846 - val_loss: 0.4064 - val_accuracy: 0.9211\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0328 - accuracy: 0.9846 - val_loss: 0.5499 - val_accuracy: 0.9211\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0314 - accuracy: 0.9846 - val_loss: 0.5270 - val_accuracy: 0.9211\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0327 - accuracy: 0.9846 - val_loss: 0.4883 - val_accuracy: 0.9211\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0335 - accuracy: 0.9824 - val_loss: 0.6262 - val_accuracy: 0.9123\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0357 - accuracy: 0.9802 - val_loss: 0.4370 - val_accuracy: 0.9211\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0561 - accuracy: 0.9648 - val_loss: 0.6841 - val_accuracy: 0.9123\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0856 - accuracy: 0.9758 - val_loss: 0.7894 - val_accuracy: 0.9123\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0603 - accuracy: 0.9604 - val_loss: 0.2645 - val_accuracy: 0.9035\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0691 - accuracy: 0.9626 - val_loss: 0.3250 - val_accuracy: 0.8860\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.9670 - val_loss: 0.5359 - val_accuracy: 0.8947\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0665 - accuracy: 0.9648 - val_loss: 0.3522 - val_accuracy: 0.8860\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0542 - accuracy: 0.9626 - val_loss: 0.3175 - val_accuracy: 0.8947\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.9604 - val_loss: 0.2426 - val_accuracy: 0.8947\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0551 - accuracy: 0.9604 - val_loss: 0.2356 - val_accuracy: 0.9035\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9714 - val_loss: 0.2796 - val_accuracy: 0.9298\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.9780 - val_loss: 0.5019 - val_accuracy: 0.9035\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 0.9802 - val_loss: 0.5711 - val_accuracy: 0.9035\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.9824 - val_loss: 0.5910 - val_accuracy: 0.9123\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0367 - accuracy: 0.9846 - val_loss: 0.6302 - val_accuracy: 0.9123\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0316 - accuracy: 0.9846 - val_loss: 0.6323 - val_accuracy: 0.9211\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0299 - accuracy: 0.9890 - val_loss: 0.8129 - val_accuracy: 0.9211\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0353 - accuracy: 0.9824 - val_loss: 0.6407 - val_accuracy: 0.9211\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0357 - accuracy: 0.9868 - val_loss: 0.5187 - val_accuracy: 0.9123\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0319 - accuracy: 0.9868 - val_loss: 0.6869 - val_accuracy: 0.9035\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0541 - accuracy: 0.9714 - val_loss: 0.8942 - val_accuracy: 0.9035\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9670 - val_loss: 0.7758 - val_accuracy: 0.9123\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1212 - accuracy: 0.9582 - val_loss: 0.7555 - val_accuracy: 0.9123\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0690 - accuracy: 0.9648 - val_loss: 0.4622 - val_accuracy: 0.9123\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.9516 - val_loss: 0.3193 - val_accuracy: 0.9123\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 0.9714 - val_loss: 0.5484 - val_accuracy: 0.9035\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0850 - accuracy: 0.9670 - val_loss: 0.2657 - val_accuracy: 0.9123\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0521 - accuracy: 0.9714 - val_loss: 0.1889 - val_accuracy: 0.9123\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0606 - accuracy: 0.9692 - val_loss: 0.2170 - val_accuracy: 0.9123\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0496 - accuracy: 0.9714 - val_loss: 0.2781 - val_accuracy: 0.9123\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 0.9736 - val_loss: 0.2747 - val_accuracy: 0.9123\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0396 - accuracy: 0.9736 - val_loss: 0.3338 - val_accuracy: 0.9035\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9736 - val_loss: 0.4199 - val_accuracy: 0.9035\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0384 - accuracy: 0.9714 - val_loss: 0.3935 - val_accuracy: 0.9035\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0352 - accuracy: 0.9802 - val_loss: 0.3949 - val_accuracy: 0.9298\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0462 - accuracy: 0.9780 - val_loss: 0.6318 - val_accuracy: 0.9298\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 0.9714 - val_loss: 0.2353 - val_accuracy: 0.9474\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9714 - val_loss: 0.3726 - val_accuracy: 0.9298\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9758 - val_loss: 0.3062 - val_accuracy: 0.9298\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0489 - accuracy: 0.9736 - val_loss: 0.2300 - val_accuracy: 0.9298\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0495 - accuracy: 0.9802 - val_loss: 0.4809 - val_accuracy: 0.9298\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0809 - accuracy: 0.9736 - val_loss: 0.3539 - val_accuracy: 0.9386\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9692 - val_loss: 0.1796 - val_accuracy: 0.9123\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0548 - accuracy: 0.9736 - val_loss: 0.2796 - val_accuracy: 0.9298\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 0.9780 - val_loss: 0.4158 - val_accuracy: 0.9298\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0368 - accuracy: 0.9802 - val_loss: 0.4264 - val_accuracy: 0.9298\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 0.9824 - val_loss: 0.4366 - val_accuracy: 0.9298\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9824 - val_loss: 0.5252 - val_accuracy: 0.9298\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0305 - accuracy: 0.9802 - val_loss: 0.6104 - val_accuracy: 0.9298\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0297 - accuracy: 0.9824 - val_loss: 0.5523 - val_accuracy: 0.9298\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0294 - accuracy: 0.9846 - val_loss: 0.5890 - val_accuracy: 0.9298\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0301 - accuracy: 0.9824 - val_loss: 0.5802 - val_accuracy: 0.9298\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0287 - accuracy: 0.9846 - val_loss: 0.6136 - val_accuracy: 0.9298\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0288 - accuracy: 0.9824 - val_loss: 0.5985 - val_accuracy: 0.9298\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0296 - accuracy: 0.9846 - val_loss: 0.6415 - val_accuracy: 0.9298\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0282 - accuracy: 0.9846 - val_loss: 0.7157 - val_accuracy: 0.9298\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 0.9824 - val_loss: 0.7253 - val_accuracy: 0.9298\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0289 - accuracy: 0.9846 - val_loss: 0.7349 - val_accuracy: 0.9298\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0345 - accuracy: 0.9802 - val_loss: 0.7687 - val_accuracy: 0.9298\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0345 - accuracy: 0.9802 - val_loss: 0.5280 - val_accuracy: 0.9298\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0331 - accuracy: 0.9780 - val_loss: 0.8464 - val_accuracy: 0.9298\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0630 - accuracy: 0.9780 - val_loss: 0.7845 - val_accuracy: 0.9123\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.9714 - val_loss: 0.4744 - val_accuracy: 0.8947\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.9495 - val_loss: 0.6404 - val_accuracy: 0.9123\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9736 - val_loss: 0.5477 - val_accuracy: 0.9211\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 0.9780 - val_loss: 0.2804 - val_accuracy: 0.9211\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.9714 - val_loss: 0.5420 - val_accuracy: 0.8860\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0436 - accuracy: 0.9714 - val_loss: 0.7235 - val_accuracy: 0.9123\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0345 - accuracy: 0.9802 - val_loss: 0.6111 - val_accuracy: 0.9035\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - accuracy: 0.9956 - val_loss: 0.6606 - val_accuracy: 0.8860\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9912 - val_loss: 0.7163 - val_accuracy: 0.8947\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.6387 - val_accuracy: 0.8947\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9934 - val_loss: 0.5815 - val_accuracy: 0.9035\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.6952 - val_accuracy: 0.9035\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0187 - accuracy: 0.9934 - val_loss: 0.8268 - val_accuracy: 0.9035\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0175 - accuracy: 0.9934 - val_loss: 0.9400 - val_accuracy: 0.9035\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0177 - accuracy: 0.9934 - val_loss: 0.8773 - val_accuracy: 0.8947\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0171 - accuracy: 0.9934 - val_loss: 0.8639 - val_accuracy: 0.9211\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0174 - accuracy: 0.9934 - val_loss: 0.8571 - val_accuracy: 0.9298\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0176 - accuracy: 0.9934 - val_loss: 0.9154 - val_accuracy: 0.9211\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9934 - val_loss: 1.0070 - val_accuracy: 0.9211\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0172 - accuracy: 0.9934 - val_loss: 0.9888 - val_accuracy: 0.9123\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - accuracy: 0.9934 - val_loss: 1.1634 - val_accuracy: 0.9035\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 1.1683 - val_accuracy: 0.9035\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0173 - accuracy: 0.9934 - val_loss: 0.9937 - val_accuracy: 0.9123\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0198 - accuracy: 0.9912 - val_loss: 1.0845 - val_accuracy: 0.8947\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9868 - val_loss: 1.0319 - val_accuracy: 0.9035\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0332 - accuracy: 0.9802 - val_loss: 0.9752 - val_accuracy: 0.8860\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 0.9890 - val_loss: 1.3899 - val_accuracy: 0.8860\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0579 - accuracy: 0.9890 - val_loss: 0.9223 - val_accuracy: 0.8947\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0555 - accuracy: 0.9670 - val_loss: 0.4810 - val_accuracy: 0.9386\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.9626 - val_loss: 0.5856 - val_accuracy: 0.9386\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0678 - accuracy: 0.9736 - val_loss: 0.3828 - val_accuracy: 0.9386\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0394 - accuracy: 0.9868 - val_loss: 0.2839 - val_accuracy: 0.9211\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0375 - accuracy: 0.9846 - val_loss: 0.3820 - val_accuracy: 0.8947\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0325 - accuracy: 0.9824 - val_loss: 0.5344 - val_accuracy: 0.8947\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0237 - accuracy: 0.9934 - val_loss: 0.7767 - val_accuracy: 0.8947\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0233 - accuracy: 0.9912 - val_loss: 0.9057 - val_accuracy: 0.8947\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 0.9934 - val_loss: 0.9283 - val_accuracy: 0.8947\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9956 - val_loss: 1.0665 - val_accuracy: 0.8947\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 1.2538 - val_accuracy: 0.8947\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9934 - val_loss: 1.0202 - val_accuracy: 0.8947\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - accuracy: 0.9934 - val_loss: 0.9740 - val_accuracy: 0.9035\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0178 - accuracy: 0.9934 - val_loss: 0.9695 - val_accuracy: 0.9035\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0198 - accuracy: 0.9912 - val_loss: 1.1906 - val_accuracy: 0.8947\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9934 - val_loss: 1.3827 - val_accuracy: 0.8947\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0178 - accuracy: 0.9912 - val_loss: 1.4747 - val_accuracy: 0.8947\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0163 - accuracy: 0.9934 - val_loss: 1.4769 - val_accuracy: 0.8947\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0165 - accuracy: 0.9934 - val_loss: 1.5194 - val_accuracy: 0.8947\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9934 - val_loss: 1.5965 - val_accuracy: 0.8947\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 0.9934 - val_loss: 1.6513 - val_accuracy: 0.8947\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 0.9934 - val_loss: 1.5749 - val_accuracy: 0.8947\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9934 - val_loss: 1.6634 - val_accuracy: 0.8947\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0202 - accuracy: 0.9890 - val_loss: 1.8808 - val_accuracy: 0.8947\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 0.9846 - val_loss: 1.8476 - val_accuracy: 0.8947\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0647 - accuracy: 0.9824 - val_loss: 1.1904 - val_accuracy: 0.8947\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9824 - val_loss: 0.4248 - val_accuracy: 0.9123\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0679 - accuracy: 0.9758 - val_loss: 0.4405 - val_accuracy: 0.9035\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0558 - accuracy: 0.9758 - val_loss: 0.8838 - val_accuracy: 0.9123\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0392 - accuracy: 0.9780 - val_loss: 1.1063 - val_accuracy: 0.8947\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0324 - accuracy: 0.9824 - val_loss: 1.3514 - val_accuracy: 0.8860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd6d460ff60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 312
        }
      ]
    }
  ]
}